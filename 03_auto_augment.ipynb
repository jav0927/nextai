{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%nbdev_hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pete88b/nbdev_colab_helper.git\n",
      "  Cloning https://github.com/pete88b/nbdev_colab_helper.git to /tmp/pip-req-build-xes1857_\n",
      "  Running command git clone -q https://github.com/pete88b/nbdev_colab_helper.git /tmp/pip-req-build-xes1857_\n",
      "Building wheels for collected packages: nbdev-colab-helper\n",
      "  Building wheel for nbdev-colab-helper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nbdev-colab-helper: filename=nbdev_colab_helper-0.0.1-cp36-none-any.whl size=9695 sha256=88a7afd62b52c7df4bbf61dd73d411220eac3f4edce9930a3cddcbc6f56ed82b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-d1y3byhb/wheels/11/52/f4/a49fbdda142e8992bb1695aa9eb30f499294a14cfb4b753fbe\n",
      "Successfully built nbdev-colab-helper\n",
      "Installing collected packages: nbdev-colab-helper\n",
      "Successfully installed nbdev-colab-helper-0.0.1\n",
      "Connecting to google drive\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/github/nextai\n",
      "pip install fastscript==1.0.0 fastcore==1.0.8 nbdev==1.0.14\n",
      "   Collecting fastscript==1.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/60/e4/7790e3ca100841566fdc1ccee413b9a9d40629d1858d86b1b9ffbc4fa75a/fastscript-1.0.0-py3-none-any.whl\n",
      "Collecting fastcore==1.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/53/3a/b2e5e18f20cf13285d7e5a87165386e916104b5eaad8c5d5a0f8c4c76f98/fastcore-1.0.8-py3-none-any.whl\n",
      "Collecting nbdev==1.0.14\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/3c/6e05c52e16aab5a0406de7ca6c8f0df5d363f0519c7de66d25e5ef00a53a/nbdev-1.0.14-py3-none-any.whl (57kB)\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from fastscript==1.0.0) (19.3.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastscript==1.0.0) (20.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from nbdev==1.0.14) (3.13)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from nbdev==1.0.14) (4.10.1)\n",
      "Requirement already satisfied: nbconvert>=5.6.1 in /usr/local/lib/python3.6/dist-packages (from nbdev==1.0.14) (5.6.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from nbdev==1.0.14) (5.3.5)\n",
      "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from nbdev==1.0.14) (5.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastscript==1.0.0) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastscript==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->nbdev==1.0.14) (4.3.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->nbdev==1.0.14) (5.5.0)\n",
      "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->nbdev==1.0.14) (5.1.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (3.2.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (0.6.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (0.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (0.8.4)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (2.11.2)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (2.6.1)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.6.1->nbdev==1.0.14) (4.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->nbdev==1.0.14) (2.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->nbdev==1.0.14) (19.0.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev==1.0.14) (2.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4.0->nbdev==1.0.14) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->nbdev==1.0.14) (4.4.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev==1.0.14) (50.3.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev==1.0.14) (0.8.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev==1.0.14) (1.0.18)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev==1.0.14) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->nbdev==1.0.14) (4.8.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.6.1->nbdev==1.0.14) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert>=5.6.1->nbdev==1.0.14) (1.1.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->nbdev==1.0.14) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->nbdev==1.0.14) (0.6.0)\n",
      "Installing collected packages: fastscript, fastcore, nbdev\n",
      "Successfully installed fastcore-1.0.8 fastscript-1.0.0 nbdev-1.0.14 \n",
      "/content/drive/My Drive/Colab Notebooks/github/nextai\n"
     ]
    }
   ],
   "source": [
    "#%nbdev_hide\n",
    "IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "if IN_COLAB:\n",
    "  !pip install git+https://github.com/pete88b/nbdev_colab_helper.git\n",
    "  from nbdev_colab_helper.core import *\n",
    "  project_name = 'nextai'\n",
    "  init_notebook(project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # auto_agument\n",
    "\n",
    "> Implements Google AutoAugment augmentations.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp auto_augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r\u001b[K     |█                               | 10kB 34.5MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 4.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 4.9MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "!pip install fastai --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "#from fastai.vision.all import *\n",
    "from fastai import *\n",
    "import numpy as np\n",
    "\n",
    "from torch import tensor, Tensor\n",
    "import torch\n",
    "\n",
    "# For use in Auto Augment data transformations\n",
    "import random\n",
    "import torchvision.transforms.functional as FT\n",
    "from typing import *\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# Automatically sets for GPU or CPU environments\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# Convert FASTAI image basis. (-1,-1) top-left (1,1) bottom-right  to PIL image basis (0,0) top-left to (1,1) bottom-right    \n",
    "def fastai2pil_basis(b) :  return ((b + 1.)).div(2.)      # b - Bounding box(s)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 1.], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "bb = torch.tensor([-1.,-1.,1.,1], dtype=float,device=device) # Fastai\n",
    "fastai2pil_basis(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# Convert PIL image basis (0,0) top-left to (1,1) bottom-right  to FASTAI image basis. (-1,-1) top-left to (1,1) bottom-right\n",
    "def pil2fastai_basis(b):  return (b * 2.).float() - 1.    # b - Bounding box(s)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "bb = torch.tensor([0.,0.,1.,1], dtype=float,device=device) # Fastai\n",
    "out = pil2fastai_basis(bb)\n",
    "torch.all(out.eq(torch.tensor([[[-1., -1.,  1.,  1.]]], dtype=float,device=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1.,  1.,  1.], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "bb = torch.tensor([-1.,-1.,1.,1], dtype=float,device=device)\n",
    "pil2fastai_basis(fastai2pil_basis(bb))  # Loop the loop ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform an image in PIL format to Fastai tensor format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# Helper Function\n",
    "def pil2tensor(image:Image,dtype:np.dtype)->Tensor:\n",
    "    ''' Convert PIL style `image` array to torch style image tensor.\n",
    "        Imput -  image -image in PILImage form\n",
    "        output - image in FASTAI image format\n",
    "        '''\n",
    "    a = np.asarray(image)\n",
    "    if a.ndim==2 : a = np.expand_dims(a,2)\n",
    "    a = np.transpose(a, (1, 0, 2))\n",
    "    a = np.transpose(a, (2, 1, 0))\n",
    "    return torch.from_numpy(a.astype(dtype, copy=False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1600, 1200])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "im = Image.open(F'/content/drive/My Drive/IMG_1420.JPG') #  \n",
    "img = pil2tensor(im,np.float32)\n",
    "print(img.shape)\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip a bounding box along the vertical axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def flip_horizontal(bboxes): \n",
    "  ''' \n",
    "    Flips a bounding box tensor along the vertical axis \n",
    "    Input:    bboxes - 2-d tensor containing bounding boxes in the format x1y1x2y2\n",
    "    Output:   Bounding boxes flipped along the vertical axis in the format x1y1x2y2\n",
    "  '''\n",
    "  bboxes[...,[0,2]] = torch.flip(bboxes[...,[0,2]], [len(bboxes.size())-1]) * -1.     # Swap the (x) columns: 0, and 2 and change sign                                                     # Flip the sign of each of these columns\n",
    "  return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "%nbdev_hide\n",
    "bb = torch.tensor([[[0.,0.,1.,1.]]], dtype=float,device=device)\n",
    "out = flip_horizontal(bb)\n",
    "torch.all(out.eq(torch.tensor([[[-1.,0.,0.,1.]]], dtype=float,device=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "%nbdev_hide\n",
    "bb = torch.tensor([[[-0.5,-0.5,0.5,0.5]]], dtype=float,device=device)\n",
    "out = flip_horizontal(bb)\n",
    "torch.all(out.eq(torch.tensor([[[-0.5,-0.5,0.5,0.5]]], dtype=float,device=device)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "%nbdev_hide\n",
    "bb = torch.tensor([[[-1.,-1.,0.,0.]]], dtype=float,device=device)\n",
    "out = flip_horizontal(bb)\n",
    "torch.all(out.eq(torch.tensor([[[0.,-1.,1.,0.]]], dtype=float,device=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 4\n",
    "%nbdev_hide\n",
    "bb = torch.tensor([[[-1.,-1.,1.,1.]]], dtype=float,device=device)\n",
    "out = flip_horizontal(bb)\n",
    "torch.all(out.eq(torch.tensor([[[-1.,-1.,1.,1.]]], dtype=float,device=device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip a bounding box along the horinzontal axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def flip_vertical(bboxes): \n",
    "  ''' \n",
    "    Flips a bounding box tensor along the horizontal axis \n",
    "    Input:    bboxes - 2-d tensor containing bounding boxes in the format x1y1x2y2\n",
    "    Output:   Bounding boxes flipped along the horizontal axis in the format x1y1x2y2\n",
    "  '''\n",
    "  bboxes[...,[1,3]] = torch.flip(bboxes[...,[1,3]], [len(bboxes.size())-1]) * -1.     # Swap the (x) columns: 0, and 2 and change sign \n",
    "  return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "%nbdev_hide\n",
    "bb = torch.tensor([[[0.,-1.,1.,0.]]], dtype=float,device=device)\n",
    "out = flip_vertical(bb)\n",
    "torch.all(out.eq(torch.tensor([[[0.,0.,1.,1.]]], dtype=float,device=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "%nbdev_hide\n",
    "bb = torch.tensor([[[-0.5,-0.5,0.5,0.5]]], dtype=float,device=device)\n",
    "out = flip_vertical(bb)\n",
    "torch.all(out.eq(torch.tensor([[[-0.5,-0.5,0.5,0.5]]], dtype=float,device=device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flip a bounding box along the vertical axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def swap_xy_coords (bboxes):   \n",
    "  ''' swap yx coordinate sequences in bounding boxes into xy sequences, and viceversa \n",
    "      Input:    bboxes - 2-d tensor containing bounding boxes\n",
    "      Output:   Bounding boxes flipped with swapped coordinate, xy --> yx\n",
    "  '''\n",
    "  bboxes[...,[0,1]] = torch.flip(bboxes[...,[0,1]], [len(bboxes.size())-1]) \n",
    "  bboxes[...,[2,3]] = torch.flip(bboxes[...,[2,3]], [len(bboxes.size())-1])\n",
    "  return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "%nbdev_hide\n",
    "bb = torch.tensor([[[0.,1.,1.,0.]]], dtype=float,device=device)\n",
    "out = swap_xy_coords(bb)\n",
    "torch.all(out.eq(torch.tensor([[[1.,0.,0.,1.]]], dtype=float,device=device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic rotation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "def rotate_bb(bb:Tensor, rads:float): \n",
    "    ''' Rotate a bounding box (x1,y1,x2,y2) by an angle \n",
    "        Input:  bb -   bounding box  (needs to be off-cuda)\n",
    "                rads - rotation angle in radians \n",
    "    '''          \n",
    "    M = torch.tensor([                         # Rotation Matrix\n",
    "           [math.cos(rads), -math.sin(rads)],         \n",
    "           [math.sin(rads),  math.cos(rads)]\n",
    "           ] ).to(device)          \n",
    "    #return torch.mm(bb,M) \n",
    "    return torch.matmul(bb,M)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounding Box transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# SHEAR-HORIZONTALLY BOUNDING BOXES\n",
    "def shear_x_bboxes (bboxes:Tensor, factor:float):\n",
    "  ''' \n",
    "    Shear horizontally a tensor of bounding boxes\n",
    "    Input:      \n",
    "          bboxes  -      2-d tensor of bounding boxes associated with the image\n",
    "          factor  -      Factor by which the image in sheared in the horizontal direction\n",
    "    Output:\n",
    "          bboxes -       Sheared bounding boxes\n",
    "  '''\n",
    "  p =len(bboxes.shape)-1  \n",
    "  m = bboxes[(bboxes == 0.).all(p)]                                     # Retain the all-zero rows\n",
    "  bboxes = bboxes[~(bboxes == 0.).all(p)]                               # Retain the non all-zero rows\n",
    "  mag = factor                                                          # If the factor is negative, flip the boxes about the (0,0) center\n",
    "  if factor <= 0 : mag = -factor; bboxes = flip_horizontal(bboxes)      # so it can be sheared correctly (in the positive orientation)\n",
    "  bboxes = fastai2pil_basis(bboxes)                                     # Convert from Fastai basis to to PIL image basis (0,0) to (1,1)       \n",
    "  bboxes[...,[0,2]] = bboxes[...,[0,2]] + bboxes[...,[1,3]]  * mag      # Shear in the horizontal direction (to the right)\n",
    "  #bboxes[...,0] = bboxes[...,0] - bboxes[...,1]*mag\n",
    "  #bboxes[...,2] = bboxes[...,2] - bboxes[...,3]*mag\n",
    "  bboxes = pil2fastai_basis(bboxes)                                     # Convert to FASTAI image basis. Top-left (-1,-1) to Bottom-right (1,1)\n",
    "  if factor <= 0 : bboxes = flip_horizontal(bboxes)                     # If factor is negative, restore the boxes to the original orientation\n",
    "  bboxes = torch.clamp(bboxes, -1, 1)                                   # Clamp coordinates to [-1, 1]\n",
    "  \n",
    "  return torch.cat([m, bboxes], dim=0)                                # Graft the all-zero rows back to the bounding box array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1250, -0.2500,  1.0000,  0.7500]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = torch.tensor([[-0.25,-0.25,0.75,0.75]], dtype=float,device=device)\n",
    "out = shear_x_bboxes(bb, 0.5); out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "# ROTATE BOUNDING BOXES\n",
    "def rotate_bboxes(bboxes:Tensor, degrees:float):\n",
    "  ''' \n",
    "    Rotate bounding boxes (in sync with a rotated image)\n",
    "    Input:\n",
    "        bboxes :       tensor of bounding boxes in the format x1,y1,x2,y2\n",
    "        degrees :      Angle in degrees to rotate the box as float \n",
    "    Output:\n",
    "        bboxes         tensor of rotated bounding boxes\n",
    "  '''\n",
    "  rads = math.radians(degrees)                                          # Convert degrees to radians   \n",
    "  p =len(bboxes.shape)-1                                                # nNmber of dimensions in bboxes\n",
    "  m = bboxes[(bboxes == 0.).all(p)]                                     # Retain the all-zero rows of the bounding box\n",
    "  bboxes = bboxes[~(bboxes == 0.).all(p)]                               # Retain the non all-zero rows of the bounding box\n",
    "  lgt = abs(bboxes[...,[0]] - bboxes[...,[2]])                          # Calculate the length of the box in the x axis\n",
    "  mag = rads                                                            # If degrees is negative, flip the boxes about the (0,0) center\n",
    "  if degrees <= 0 : mag = -rads; bboxes = flip_horizontal(bboxes)       # so it can be rotated correctly (in the positive orientation)\n",
    "  bboxes = bboxes.reshape(-1,2)                                         # Put tensor into a (n x 2) vertical array\n",
    "  bboxes = rotate_bb(bboxes, mag)                                       # Rotate the bounding box by the magnitude given\n",
    "  bboxes = bboxes.reshape(-1,4)                                         # Restore coordinates to fastai image basis \n",
    "  bboxes [...,[1]] = bboxes [...,[1]] - (lgt)*math.sin(mag)             # Calculate the delta-lenght to add and substract to \n",
    "  bboxes [...,[3]] = bboxes [...,[3]] + (lgt)*math.sin(mag)             #   the y coordinates to compensate for the rotation\n",
    "  if degrees <= 0 : bboxes = flip_horizontal(bboxes)                    # If degrees is negative, restore the boxes to the original orientation\n",
    "  bboxes = torch.clamp(bboxes, -1, 1)                                   # Clamp coordinates to [-1, 1]\n",
    "\n",
    "  return torch.cat([m, bboxes], dim=0)                         # Graft the all-zero rows back to the bounding box and return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  1.0000,  1.0000],\n",
      "        [ 0.0000,  0.0000,  0.5000,  0.5000],\n",
      "        [-0.5000, -0.5000,  0.5000,  0.5000],\n",
      "        [ 0.0000, -0.5000,  0.7500,  0.2500],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "bboxes = torch.tensor([[0.,0.,1.,1.],[0.,0.,0.5,0.5],[-0.5,-0.5,0.5,0.5],[0.,-0.5,0.75,0.25],[0.,0.,0.,0.],[0.,0.,0.,0.]],device=device)\n",
    "print(bboxes)\n",
    "degrees = 45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.7071,  1.0000,  0.7071],\n",
       "        [ 0.0000, -0.3536,  0.7071,  0.3536],\n",
       "        [-0.7071, -0.7071,  0.7071,  0.7071],\n",
       "        [-0.3536, -0.8839,  0.7071,  0.1768]], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "bboxes = rotate_bboxes(bboxes, degrees) ; bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class ImageNetPolicy():\n",
    "    '''\n",
    "    Augmentation policy for the ImageNet Dataset.\n",
    "    (As per the paper Learning Data Augmentation Strategies for Object detection. Barret Zoph, et. al. 6/26/2019)\n",
    "    The Policy is composed of a series of sub-policies. \n",
    "    Each sub-policy contains two (2) augmentation steps. i. e. 'posterize', 'rotate'\n",
    "    Each step consists of:\n",
    "          (1) an operation i.e. 'posterize', \n",
    "          (2) probability of application. i.e. 0.4, and\n",
    "          (3) magnitude indicating the intensity of the operation.i.e 8\n",
    "    Author:  J. Adolfo Villalobos @ 2020 \n",
    "    '''\n",
    "    def __init__(self, fillcolor=(128, 128, 128)):\n",
    "        \n",
    "        self.policy = [\n",
    "            SubPolicy(\"posterize\", 0.4, 8, \"rotate\",       0.6, 9, fillcolor),\n",
    "            SubPolicy(\"solarize\",  0.6, 5, \"autocontrast\", 0.6, 5, fillcolor),\n",
    "            SubPolicy(\"equalize\",  0.8, 8, \"equalize\",     0.6, 3, fillcolor),\n",
    "            SubPolicy(\"posterize\", 0.6, 7,\"posterize\",     0.6, 6, fillcolor),\n",
    "            SubPolicy(\"equalize\",  0.4, 7,\"solarize\",      0.2, 4, fillcolor),\n",
    "\n",
    "            SubPolicy(\"equalize\",  0.4, 4, \"rotate\",       0.8, 8, fillcolor),\n",
    "            SubPolicy(\"solarize\",  0.6, 3, \"equalize\",     0.6, 7, fillcolor),\n",
    "            SubPolicy(\"posterize\", 0.8, 5, \"equalize\",     1.0, 2, fillcolor),\n",
    "            SubPolicy(\"rotate\",    0.2, 3, \"solarize\",     0.6, 8, fillcolor),\n",
    "            SubPolicy(\"equalize\",  0.6, 8, \"posterize\",    0.4, 6, fillcolor),\n",
    "\n",
    "            SubPolicy(\"rotate\",    0.8, 8, \"color\",        0.4, 0, fillcolor),\n",
    "            SubPolicy(\"rotate\",    0.4, 9, \"equalize\",     0.6, 2, fillcolor),\n",
    "            SubPolicy(\"equalize\",  0.0, 7, \"equalize\",     0.8, 8, fillcolor),\n",
    "            SubPolicy(\"invert\",    0.6, 4, \"equalize\",     1.0, 8, fillcolor),\n",
    "            SubPolicy(\"color\",     0.6, 4, \"contrast\",     1.0, 8, fillcolor),\n",
    "\n",
    "            SubPolicy(\"rotate\",    0.8, 8, \"color\",        1.0, 2, fillcolor),\n",
    "            SubPolicy(\"color\",     0.8, 8, \"solarize\",     0.8, 7, fillcolor),\n",
    "            SubPolicy(\"sharpness\", 0.4, 7, \"invert\",       0.6, 8, fillcolor),\n",
    "            SubPolicy(\"shearX\",    0.6, 5, \"equalize\",     1.0, 9, fillcolor),\n",
    "            SubPolicy(\"color\",     0.4, 0, \"equalize\",     0.6, 3, fillcolor),\n",
    "\n",
    "            SubPolicy(\"equalize\",  0.4, 7, \"solarize\",     0.2, 4, fillcolor),\n",
    "            SubPolicy(\"solarize\",  0.6, 5, \"autocontrast\", 0.6, 5, fillcolor),\n",
    "            SubPolicy(\"invert\",    0.6, 4, \"equalize\",     1.0, 8, fillcolor),\n",
    "            SubPolicy(\"color\",     0.6, 4, \"contrast\",     1.0, 8, fillcolor),\n",
    "            SubPolicy(\"equalize\",  0.8, 8, \"equalize\",     0.6, 3, fillcolor)\n",
    "        ]\n",
    "            \n",
    "    \n",
    "    def __call__(self, x, y):\n",
    "      '''Fetch a random sub-policy\n",
    "          Inputs: x - XXX, y - XXXX\n",
    "          Outputs: Selected policy\n",
    "      '''\n",
    "      policy_idx = random.randint(0, len(self.policy) - 1)\n",
    "      return self.policy[policy_idx](x, y)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"AutoAugment Policy for the ImageNet Dataset. \"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "class SubPolicy():\n",
    "    def __init__(self, operation1, p1, magnitude_idx1, operation2, p2, magnitude_idx2, fillcolor=(128, 128, 128)):\n",
    "        '''\n",
    "        The magnitude that is specified for each subpolicy item is a number from 1 to 10.\n",
    "        This number translates to a separate measure which varies for each operation. The specific measure\n",
    "        is picked up from a range of uniformly spaced physical attribute values according to the dictionary below.\n",
    "        '''\n",
    "        ranges = {\n",
    "            \"shearX\": np.linspace(-0.3, 0.3, 10),     \n",
    "            \"shearY\": np.linspace(-0.3, 0.3, 10),     \n",
    "            \"translateX\": np.linspace(-150, 150 / 331, 10),\n",
    "            \"rotate\": np.linspace(-30, 30, 10),        \n",
    "            \"color\": np.linspace(0.1, 1.9, 10),\n",
    "            \"posterize\": np.round(np.linspace(8, 4, 10), 0).astype(np.int),\n",
    "            \"solarize\": np.linspace(256, 0, 10),\n",
    "            \"contrast\": np.linspace(0.1, 1.9, 10),\n",
    "            \"sharpness\": np.linspace(0.1, 1.9, 10),\n",
    "            \"brightness\": np.linspace(0.1, 1.9, 10),\n",
    "            \"autocontrast\": [0] * 10,\n",
    "            \"equalize\": [0] * 10,\n",
    "            \"invert\": [0] * 10\n",
    "        }\n",
    "       \n",
    "        # Custom rotate with fill       \n",
    "        def rotate_with_fill(img:PILImage, yb, mag):\n",
    "            ob = rotate_bboxes(yb, mag, y_first=False)\n",
    "            return [img.convert(\"RGBA\").rotate(mag, resample=Image.BICUBIC, fillcolor=(128,128,128)).convert(img.mode), ob]    # Rotate the image\n",
    "        \n",
    "        # Shear horizontal\n",
    "        def shear_horizontal (img:PILImage, yb, mag): \n",
    "            trb = mag*random.choice([-1, 1])\n",
    "            tri = (1, -trb, 0, 0, 1, 0)\n",
    "            b_tf = img.transform(img.size, Image.AFFINE, tri, Image.BICUBIC,fillcolor=(128,128,128) )\n",
    "            ob = shear_x_bboxes (yb, trb, y_first=False)                 \n",
    "            return [b_tf, ob]\n",
    "\n",
    "        # Transform functions\n",
    "        func = {\n",
    "\n",
    "            \"rotate\": lambda img, yp, magnitude: rotate_with_fill(img, yp, magnitude),\n",
    "            \"shearX\": lambda img, yp, magnitude: shear_horizontal(img, yp, magnitude), \n",
    "            \"color\": lambda img, yp, magnitude: [ImageEnhance.Color(img).enhance(magnitude), yp],\n",
    "            \"posterize\": lambda img, yp, magnitude: [ImageOps.posterize(img, magnitude), yp],\n",
    "            \"solarize\": lambda img, yp, magnitude: [ImageOps.solarize(img, magnitude), yp],\n",
    "            \"contrast\": lambda img, yp, magnitude: [ImageEnhance.Contrast(img).enhance(\n",
    "                1 + magnitude * random.choice([-1, 1])), yp],\n",
    "            \"sharpness\": lambda img, yp, magnitude: [ImageEnhance.Sharpness(img).enhance(\n",
    "                1 + magnitude * random.choice([-1, 1])), yp],\n",
    "            \"brightness\": lambda img, yp, magnitude: [ImageEnhance.Brightness(img).enhance(\n",
    "                1 + magnitude * random.choice([-1, 1])), yp],\n",
    "            \"autocontrast\": lambda img, yp, magnitude: [ImageOps.autocontrast(img), yp],\n",
    "            \"equalize\": lambda img, yp, magnitude: [ImageOps.equalize(img, mask=None), yp],\n",
    "            \"invert\": lambda img, yp, magnitude: [ImageOps.invert(img), yp]\n",
    "        }\n",
    "        \n",
    "        # Probabilities\n",
    "        self.p1 = p1; self.p2 = p2\n",
    "        \n",
    "        #  Fetch a Fastai transform corresponding to the given subpolicy step operation\n",
    "        self.operation1 = func[operation1]; self.operation2 = func[operation2]\n",
    "        self.magnitude1 = ranges[operation1][magnitude_idx1]; self.magnitude2 = ranges[operation2][magnitude_idx2]\n",
    "        \n",
    "    # Randomized filtering\n",
    "    def __call__(self, x, y):       \n",
    "        # Transfor image tensor to PIL image\n",
    "        img = FT.to_pil_image(x.data.cpu(), mode='RGB')     \n",
    "        # Fetch a Fastai-formatted transform corresponnding to the given Subpolicy\n",
    "        if random.random() < self.p1: img, y = self.operation1(img, y, self.magnitude1)\n",
    "        if random.random() < self.p2: img, y = self.operation2(img, y, self.magnitude2)\n",
    "        # Revert to FASTAI Image format \n",
    "        img = pil2tensor(img, dtype=np.float32) #.div(255)    \n",
    "        return img, y      # returns the transformed image and corresponding bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_hide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00_vision_core.ipynb.\n",
      "Converted 01_anchor_boxes.ipynb.\n",
      "Converted 02_inference.ipynb.\n",
      "Converted 03_auto_augment.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": "<h4 id=\"rotate_bboxes\" class=\"doc_header\"><code>rotate_bboxes</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>rotate_bboxes</code>(**`bboxes`**:`Tensor`, **`degrees`**:`float`)\n\nRotate bounding boxes (in sync with a rotated image)\nInput:\n    bboxes :       tensor of bounding boxes in the format x1,y1,x2,y2\n    degrees :      Angle in degrees to rotate the box as float \nOutput:\n    bboxes         tensor of rotated bounding boxes",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<h4 id=\"shear_x_bboxes\" class=\"doc_header\"><code>shear_x_bboxes</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>shear_x_bboxes</code>(**`bboxes`**:`Tensor`, **`factor`**:`float`)\n\nShear horizontally a tensor of bounding boxes\nInput:      \n      bboxes  -      2-d tensor of bounding boxes associated with the image\n      factor  -      Factor by which the image in sheared in the horizontal direction. Range (0,1)\nOutput:\n      bboxes -       Sheared bounding boxes",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<h4 id=\"rotate_bb\" class=\"doc_header\"><code>rotate_bb</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>rotate_bb</code>(**`bb`**:`Tensor`, **`rads`**:`float`)\n\nRotate a bounding box (x1,y1,x2,y2) by an angle \nInput:  bb -   bounding box  (needs to be off-cuda)\n        rads - rotation angle in radians ",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<h4 id=\"swap_xy_coords\" class=\"doc_header\"><code>swap_xy_coords</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>swap_xy_coords</code>(**`bboxes`**)\n\nswap yx coordinate sequences in bounding boxes into xy sequences, and viceversa \nInput:    bboxes - 2-d tensor containing bounding boxes\nOutput:   Bounding boxes flipped with swapped coordinate, xy --> yx",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<h4 id=\"flip_horizontal\" class=\"doc_header\"><code>flip_horizontal</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>flip_horizontal</code>(**`bboxes`**)\n\nFlips a bounding box tensor along the vertical axis \nInput:    bboxes - 2-d tensor containing bounding boxes in the format x1y1x2y2\nOutput:   Bounding boxes flipped along the vertical axis in the format x1y1x2y2",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<h4 id=\"rotate_bboxes\" class=\"doc_header\"><code>rotate_bboxes</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>rotate_bboxes</code>(**`bboxes`**:`Tensor`, **`degrees`**:`float`)\n\nRotate bounding boxes (in sync with a rotated image)\nInput:\n    bboxes :       tensor of bounding boxes in the format x1,y1,x2,y2\n    degrees :      Angle in degrees to rotate the box as float \nOutput:\n    bboxes         tensor of rotated bounding boxes",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<h4 id=\"rotate_bboxes\" class=\"doc_header\"><code>rotate_bboxes</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>rotate_bboxes</code>(**`bboxes`**:`Tensor`, **`degrees`**:`float`)\n\nRotate bounding boxes (in sync with a rotated image)\nInput:\n    bboxes :       tensor of bounding boxes in the format x1,y1,x2,y2\n    degrees :      Angle in degrees to rotate the box as float \nOutput:\n    bboxes         tensor of rotated bounding boxes",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": "<h4 id=\"rotate_bboxes\" class=\"doc_header\"><code>rotate_bboxes</code><a href=\"__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n\n> <code>rotate_bboxes</code>(**`bboxes`**:`Tensor`, **`degrees`**:`float`)\n\nRotate bounding boxes (in sync with a rotated image)\nInput:\n    bboxes :       tensor of bounding boxes in the format x1,y1,x2,y2\n    degrees :      Angle in degrees to rotate the box as float \nOutput:\n    bboxes         tensor of rotated bounding boxes",
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nbdev import *\n",
    "show_doc(rotate_bboxes)\n",
    "show_doc(shear_x_bboxes)\n",
    "show_doc(rotate_bb)\n",
    "show_doc(swap_xy_coords)\n",
    "show_doc(flip_horizontal)\n",
    "show_doc(rotate_bboxes)\n",
    "show_doc(rotate_bboxes)\n",
    "show_doc(rotate_bboxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
